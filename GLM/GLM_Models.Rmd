---
title: "STAT 400 - GLM Analysis"
author: "Ishan Agrahar, Jake Sturges, Noah Tobias, Prajwal Bhandari"
date: "2025-12-03"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = here::here())
```

## FRONT MATTER
```{r, message = FALSE}
# Libraries
library(tidyverse)
library(pROC)
library(car)
library(caret)
# NOTE: here::here() will use STAT_400-Final_Project/ as the root directory
NBATeamData = read.csv(here::here("glm","data", "CleanedData", "NBATeamData.csv"))
```

## Comparing Predictive Power and Signal Strength NBA Playoff Appearance from Defensive and Offensive Variable Sets.

For the remainder of the analysis, we will answer the following question by comparing GLMs predicting if a team makes it to the NBA Playoffs or not: What set of variables, defensive or offensive, have higher predictive strength for playoff appearance? To do the analysis, we will compare three different models: one with only defensive statistics, one with only offensive statistics, and one with the two combined. For model selection, we will use `step()` with two-way variable selection with AIC as the metric.

When considering the variables in the dataset, some variables have both attempts and the number made (for three pointers, field goals, etc.). We will use the number made since the attempts do not show the full picture and are still highly correlated with the number made.

Finally, there is one key assumption to make for the analysis: a team's performance in one given year is independent of their performance in the year prior. We acknowledge that this is not necessarily true in reality and we are taking on this assumption for the purposes of the project.


First we will make an 80/20 split for the data and define the sets of variables.

```{r}
# make split
set.seed(0) # for reproducibility
idx = sample(1:nrow(NBATeamData), floor(0.8*nrow(NBATeamData)))
train = NBATeamData[idx,]
val = NBATeamData[-idx,]

defense = c("DREB", "STL", "BLK", "BLK","PF", "PlayoffAppearanceIndicator")
offense = c("FGM", "FTM", "AST", "OREB", "BLKA", "TOV", "PTS", "PlayoffAppearanceIndicator")
both = c(defense, offense)[-13] # remove second indicator
```

Now we will define the training sets for the three models, build the null and full models, then run stepwise selection with AIC as the criterion.

```{r}
train_defense = train %>% select(all_of(defense))
train_offense = train %>% select(all_of(offense))
train_all = train %>% select(all_of(both))

defense_full = glm(PlayoffAppearanceIndicator ~ ., data = train_defense, family = binomial)
defense_null = glm(PlayoffAppearanceIndicator ~ 1, data = train_defense, family = binomial)
offense_full = glm(PlayoffAppearanceIndicator ~ ., data = train_offense, family = binomial)
offense_null = glm(PlayoffAppearanceIndicator ~ 1, data = train_offense, family = binomial)
all_full = glm(PlayoffAppearanceIndicator ~ ., data = train_all, family = binomial)
all_null = glm(PlayoffAppearanceIndicator ~ 1, data = train_all, family = binomial)

defense_final = step(defense_null, scope = list(lower = defense_null, upper = defense_full), direction = 'both', k = 2, trace = 0)
offense_final = step(offense_null, scope = list(lower = offense_null, upper = offense_full), direction = 'both', k = 2, trace = 0)
all_final = step(all_null, scope = list(lower = all_null, upper = all_full), direction = 'both', k = 2, trace = 0)
```

Lets now take a look at the three final models produced and the predictor variables included, starting with the defense model. 

```{r}
summary(defense_final)

# check multicollinearity
car::vif(defense_final)
```

In the model that only uses the defensive variables to predict playoff appearances for a team, we see that only defensive rebound and steals are significant predictors at the 5\% level. The negative on the `PF` coefficient indicates that personal fouls reduce the odds of winning. We will exponentiate the model coefficients for more interpretable meanings and confidence intervals. Multicollinearity is also not an issue in this model as all the variance inflation factors are near 1.

```{r}
exp(confint(defense_final))
```

Using profile confidence intervals at a 95\% confidence level, we can interpret the coefficients as such: a 1 rebound increase in the defensive rebound mean changes the odds of making the playoffs by a factor between 1.20 and 1.57, each +1 increase in the steal mean changes the odds of making the playoffs by a factor between 1.32 and 2.45, each +1 increase in the mean personal fouls changes the odds of making the playoffs by a factor between 0.68 and 0.96 which is a reduction, and finally each +1 block in the mean changes the odds of making it to the playoffs by a factor between 0.97 and 1.88. 

Next, we will examine the model with only offensive variables. 

```{r}
summary(offense_final)

car::vif(offense_final)
```

Here, we see 4 predictors: blocks against, free throws made, turnovers, and field goals made, of which only two are significant at the 5\% level with blocks against and free throws made being the most significant. Blocks against and turnovers are negative indicating a reduction in the log odds and odds. Like before, multicollinearity is also not an issue in this model as all the variance inflation factors are near 1.

```{r}
exp(confint(offense_final))
```

At a 95\% confidence level, we can make the following inferencs. For a +1 increase in the mean blocks against, the odds of making the playoffs changes byt a factor between 0.16 and 0.39, indicating a reduction in odds. For a +1 increase in mean free throws made, the odds of making the playoffs change by a factor between 1.23 and 1.69. For a +1 increase in mean turnovers, the odds of making it to the playoffs change by a factor between 0.60 and 0.96, indicating a reduction in odds. Finally for a +1 increase in mean field goals made, the odds of making it to the playoffs change by a factor between 0.98 and 1.20.

Finally, we will consider the final model including both sets of variables.

```{r}
summary(all_final)

car::vif(all_final)
```

When we consider the model created with both sets of variables, the picture changes. Out of all 12 variables, only 7 were selected and only 5 are significant predictors at the 5\% level. The 5 significant predictors are blocks against, free throws made, turnovers, steals, defensive rebounds. Just like the two previous models, multicollinearity is not an issue in this model as all the variance inflation factors are near 1. The highest value is 1.70, but this is still a healthy metric for multiple regression models. 

```{r}
exp(confint(all_final))
```
At a 95\% confidence level, we can make inferences in the same manner as above but what is more interesting is seeing which statistics reduce the odds of making it to the playoffs, and which ones increase odds. Team statistics that significantly reduce odds of winning for a +1 increase in mean statistic are blocks against and turnovers, while the variables that significantly increase the odds of making the playoffs for a +1 increase mean stats are free throws made, steals, and defensive rebounds.

Now we will use the models to make predictions and show confusion matrices as well as ROC curves, to compare predictive strength. Of course, we expect the model with both sets of variables to perform the best, but it is still in our interest to compare the 'offense model' again the 'defense model'

```{r}
pprobs_defense = predict(defense_final, newdata = val, type = "response")
pprobs_offense = predict(offense_final, newdata = val, type = "response")
pprobs_all     = predict(all_final,     newdata = val, type = "response")

# set threshold at 0.5 
thr = 0.5

pred_def  = ifelse(pprobs_defense >= thr, 1, 0)
pred_off  = ifelse(pprobs_offense >= thr, 1, 0)
pred_all  = ifelse(pprobs_all     >= thr, 1, 0)

cm_def = confusionMatrix(factor(pred_def), factor(val$PlayoffAppearanceIndicator), positive = "1")
cm_off = confusionMatrix(factor(pred_off), factor(val$PlayoffAppearanceIndicator), positive = "1")
cm_all = confusionMatrix( factor(pred_all), factor(val$PlayoffAppearanceIndicator), positive = "1")

# Extract convenience metrics
metrics = data.frame(
  Model     = c("Defense", "Offense", "Combined"),
  Accuracy  = c(cm_def$overall["Accuracy"],  cm_off$overall["Accuracy"],  cm_all$overall["Accuracy"]),
  Precision = c(cm_def$byClass["Precision"], cm_off$byClass["Precision"], cm_all$byClass["Precision"]),
  Recall    = c(cm_def$byClass["Recall"],    cm_off$byClass["Recall"],    cm_all$byClass["Recall"]),
  F1        = c(cm_def$byClass["F1"],        cm_off$byClass["F1"],        cm_all$byClass["F1"])
)

print(metrics)
```

For all of the metrics above, the offense model actually outperformed the defense model.  

Now we will look at the ROC Curves and compare the AUC of the models.

```{r, message = FALSE}
roc_def = roc(val$PlayoffAppearanceIndicator, pprobs_defense)
roc_off = roc(val$PlayoffAppearanceIndicator, pprobs_offense)
roc_all = roc(val$PlayoffAppearanceIndicator, pprobs_all)
```

```{r}
plot(roc_def, col = "red", legacy.axes = TRUE, print.auc = TRUE, print.auc.y = 0.4)
plot(roc_off, col = "blue", add = TRUE, print.auc = TRUE, print.auc.y = 0.3)
plot(roc_all, col = "darkgreen", add = TRUE, print.auc = TRUE, print.auc.y = 0.2)

legend("bottomright",
       legend = c("Defense", "Offense", "Combined"),
       col    = c("red", "blue", "darkgreen"),
       lwd    = 2)
```

The ROC curves show that both defense and offense are necessary to predict playoff appearances in NBA teams. Although in this case, the offense model has a much higher AUC (by 0.08), we acknowledge that this is highly sensitive to the seed used and a more thorough analysis should utilize cross validation or Monte Carlo simulation to produce a more complete picture of how these statistics behave and what their true predictive powers are, when separating offensive and defensive team statistics.
