---
title: "STAT 400 Final Project Report"
author: "Ishan Agrahar, Jake Sturges, Noah Tobias, Prajwal Bhandari"
date: "2025-12-09"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Front Matter

```{r, message = FALSE}
# Libraries
library(tidyverse)
library(pROC)
library(car)
library(caret)
library(janitor)
library(skimr)
library(GGally)
library(glmnet)
library(lme4)

# GLM Dataset Read-In
## Raw Data Source Link: https://github.com/NocturneBear/NBA-Data-2010-2024/blob/main/regular_season_totals_2010_2024.csv
NBAGameData <- read.csv("GLM/data/RawData/regular_season_totals_2010_2024.csv")
## I manually made a csv from this site using Google Sheets: https://basketball.realgm.com/nba/playoffs/history/2010
NBAPlayoffTeamsPerYear <- read.csv("GLM/data/RawData/NBA_Playoff_Data.csv")

# MLM Dataset Read-In
testScores <- read.csv("MLM/data/test_scores.csv")
```


# Chapter 1: Generalized Linear Models

In this chapter we will examine a dataset containing NBA team statistics and if they made the playoffs or not. A single observation in this dataset will be a NBA team during a given season. For the analysis, we will answer the following question by comparing GLMs predicting if a team makes it to the NBA Playoffs or not: What set of variables, defensive or offensive, have higher predictive strength for playoff appearance? 

To do the analysis, we will compare three different models: one with only defensive statistics, one with only offensive statistics, and one with the two combined. For model selection, we will use `step()` with two-way variable selection with AIC as the metric.

Before making any models, we will conduct the necessary data wrangling and exploratory analysis.

## The Raw Data

The dataset we are working with was created by combining two datasets: NBATeamData and NBAPlayoffTeansPerYear, both retrieved from their respective links. Joining these two tables allowed us to use the variables in the first dataset to model playoff appearance in NBA teams. 

## Data Wrangling

For the data wrangling portion of this project, our original data set had each observation as a single NBA game between 2010 and 2024, so the first thing we had to do was change an observational unit to be a team during an individual NBA season. We then combined this data set with a data set that coded for our response variable; whether a team made the NBA playoffs or not. There were no missing values in this data set and the code to make our cleaned dataset is shown below.

```{r, message = FALSE}
NBATeamData <- NBAGameData %>%
  # grouped by season and team so each observation is a team in a given season
  group_by(SEASON_YEAR,TEAM_NAME) %>%
# creating relevant variables for dataset
  summarise(FGA = mean(FGA),
            FGM = mean(FGM),
            FG_PCT = mean(FG_PCT),
            FG3M = mean(FG3M),
            FG3A = mean(FG3A),
            FG3_PCT = mean(FG3_PCT),
            FTM = mean(FTM),
            FTA = mean(FTA),
            FTPCT = mean(FT_PCT),
            OREB = mean(OREB),
            DREB = mean(DREB),
            REB = mean(REB),
            AST = mean(AST),
            TOV = mean(TOV),
            STL = mean(STL),
            BLK = mean(BLK),
            BLKA = mean(BLKA),
            PF = mean(PF),
            PFD = mean(PFD),
            PTS = mean(PTS),
            PLUS_MINUS = mean(PLUS_MINUS),
            WINPCT = mean(ifelse(WL == "W",1,0)),
            .groups = "drop") %>%
  mutate(CONFERENCE = ifelse(TEAM_NAME %in% c("Denver Nuggets","Minnesota Timberwolves","Oklahoma City Thunder","Utah Jazz","Portland Trail Blazers","Golden State Warriors","LA Clippers", "Los Angeles Clippers","Los Angeles Lakers", "Phoenix Suns","Sacramento Kings", "Dallas Mavericks","Houston Rockets","Memphis Grizzlies", "New Orleans Pelicans","San Antonio Spurs","New Orleans Hornets"), "Western", "Eastern"))

# Dataset does not include whether team has made playoffs so will need to join
## See NBAPlayoffTeamsPerYear

## I just copied and pasted playoffs occurrences, which is a comma separated string, into the Years Column so I just need to go through each team and indicate 1 if the Year is in the string and 0 otherwise.
NBAPlayoffTeamsPerYear <-
  NBAPlayoffTeamsPerYear %>%
  mutate(
    `2010-11` = ifelse(grepl("2011", Years), 1, 0),
    `2011-12` = ifelse(grepl("2012", Years), 1, 0),
    `2012-13` = ifelse(grepl("2013", Years), 1, 0),
    `2013-14` = ifelse(grepl("2014", Years), 1, 0),
    `2014-15` = ifelse(grepl("2015", Years), 1, 0),
    `2015-16` = ifelse(grepl("2016", Years), 1, 0),
    `2016-17` = ifelse(grepl("2017", Years), 1, 0),
    `2017-18` = ifelse(grepl("2018", Years), 1, 0),
    `2018-19` = ifelse(grepl("2019", Years), 1, 0),
    `2019-20` = ifelse(grepl("2020", Years), 1, 0),
    `2020-21` = ifelse(grepl("2021", Years), 1, 0),
    `2021-22` = ifelse(grepl("2022", Years), 1, 0),
    `2022-23` = ifelse(grepl("2023", Years), 1, 0),
    `2023-24` = ifelse(grepl("2024", Years), 1, 0)
  ) %>%
  pivot_longer(cols = starts_with("20"),
               names_to = "SEASON_YEAR", # For consistency with original dataset
               values_to = "PlayoffAppearanceIndicator") %>%
  rename(TEAM_NAME = Team.Name) %>%
  .[, -2] # Removing the Years Column since don't need it anymore and need to join

## Comparing team names, Uncomment below if you wanna see this
# setdiff(unique(NBAPlayoffTeamsPerYear$TEAM_NAME), unique(NBATeamData$TEAM_NAME))
# setdiff(unique(NBATeamData$TEAM_NAME), unique(NBAPlayoffTeamsPerYear$TEAM_NAME))
# Differences are "Philadelphia Sixers" "Charlotte Bobcats"   "New Jersey Nets"     "New Orleans Hornets" "Philadelphia 76ers"  "LA Clippers"

## Manually Fix Inconsistencies
NBAPlayoffTeamsPerYear$TEAM_NAME[NBAPlayoffTeamsPerYear$TEAM_NAME == "Philadelphia Sixers"] <- "Philadelphia 76ers"
NBATeamData$TEAM_NAME[NBATeamData$TEAM_NAME == "Charlotte Bobcats"] <- "Charlotte Hornets"
NBATeamData$TEAM_NAME[NBATeamData$TEAM_NAME == "New Jersey Nets"] <- "Brooklyn Nets"
NBATeamData$TEAM_NAME[NBATeamData$TEAM_NAME == "New Orleans Hornets"] <- "New Orleans Pelicans"
NBATeamData$TEAM_NAME[NBATeamData$TEAM_NAME == "LA Clippers"] <- "Los Angeles Clippers"

## Validate, Uncomment below if you wanna see this
# setdiff(unique(NBAPlayoffTeamsPerYear$TEAM_NAME), unique(NBATeamData$TEAM_NAME))
# setdiff(unique(NBATeamData$TEAM_NAME), unique(NBAPlayoffTeamsPerYear$TEAM_NAME))

## Perform Join of NBAPlayoffTeamsPerYear and NBATeamData
NBATeamData <- 
  left_join(NBATeamData,
            NBAPlayoffTeamsPerYear,
            by=c("TEAM_NAME", "SEASON_YEAR"))

## Perform save, Uncomment below if you want it
#write_csv(NBATeamData, "CleanedData/NBATeamData.csv")
```

## Description of the Data

Here we include the variables in our cleaned dataset and what they represent.

**SEASON_YEAR** - a variable describing the season in which a given team played (2011 to 2024) - Categorical, 14 Levels

**TEAM_NAME** - describes a teams name and the city they play for - Categorical, 30 Levels

**FGA** - average number of field goals attempted per game - Quantitative

**FGM** - average number of field goals made per game - Quantitative

**FG_PCT** - average field goal percentage per game - Quantitative

**FG3M** -average number of 3 pointers made per game - Quantitative

**FG3A** - average number of 3 pointers attempted per game - Quantitative

**FG3_PCT** - average 3 point percentage per game - Quantitative

**FTM** - average number of free throws made per game - Quantitative

**FTA** - average number of free throws attempted per game - Quantitative

**FTPCT** - average free throw percentage per game - Quantitative

**OREB** - average number of offensive rebounds per game - Quantitative

**DREB** - average number of defensive rebounds per game - Quantitative

**REB** - average number of rebounds per game - Quantitative

**AST** - average number of assists per game - Quantitative

**TOV** - average number of turnovers per game - Quantitative

**STL** - average number of steals per game - Quantitative

**BLK** - average number of blocks per game - Quantitative

**BLKA** - average number of blocks against per game - Quantitative

**PF** - average number of personal fouls per game - Quantitative

**PFD** - average number of personal fouls drawn per game - Quantitative

**PTS** - average number of total points per game - Quantitative

**PLUS_MINUS** - average number of points scored more than opponent - Quantitative

**WINPCT** - a teams win percentage on the season - Quantitative

**CONFERENCE** - a variable describing which conference a team is in taking values "Western" or "Eastern" - Categorical, 2 Levels

The response variable is **PlayoffAppearanceIndicator** which is a binary indicator variable with a value of 1 for if a team made the playoffs in a the specified season and 0 otherwise.

## Exploratory Data Analysis

### Create Playoff Appearance Factor Variable & Basic Summaries

```{r}
## label playoff factor once for plots below

NBATeamData <- NBATeamData %>%
  mutate(
    PlayoffAppearance = factor(
      PlayoffAppearanceIndicator,
      levels = c(0, 1),
      labels = c("No Playoffs", "Playoffs")
    )
  )

## missing values and dataset summary

colSums(is.na(NBATeamData))
glimpse(NBATeamData)
skimr::skim(NBATeamData)
head(NBATeamData)
```

Based on the above there seems to be no missing variables for any of the dataset. Based on the above there are 14 seasons worth of data (2010-2024). For our research the most important variable that we are trying to predict is playoff appearance, as this indicates whether a team made/will make the playoffs based on our model. While as of right now its not clear which variables will be most important, some that will likely have a high impact are `PTS`, `PLUS_MINUS`, `FG_PCT`, and `FG3_PCT`. One variable purposefully excluded from that is `WINPCT` as using that is kind of pointless in our prediction since `WINCPT` directly indicates playoff teams as the 8 highest `WINPCT` teams in each conference automatically make the playoffs.

## Univariate EDA 

We will focus on two variables of interest since bivariate will likely provide better insights

### Distribution of Win Percentages by teams over 2010-2024 Seasons

```{r}
## Win pct for teams

ggplot(NBATeamData, aes(x = WINPCT)) +
geom_histogram(bins = 30, fill = "steelblue", color = "white") +
labs(
title = "Distribution of Win Percentage",
x = "Win %",
y = "Count"
)
```

Win percentage seems to be centered slightly above 50% with a decent left skew. As a sports fan this makes sense as extremely low values for win % can be pretty common, while extremely high win %'s are much more rare and this is clearly seen as only one team crosses 85.00% win pct and it was the 73-9 Golden State Warriors in 2015-2016, while at least 5 teams had sub 15.00% win percentages over the same time period.  


### Points Per Game

```{r}
## Points per game for teams

ggplot(NBATeamData, aes(x = PTS)) +
geom_histogram(bins = 30, fill = "darkgreen", color = "white") +
labs(
title = "Distribution of Points per Game",
x = "Points per Game",
y = "Count"
)

```

Points per Game seems to be centered around 105 points with certain teams averaging as little as 87 points per game, with others averaging as high as 123 points per game. One prediction we have is that teams which score more have a higher likelihood of making the playoffs (obviously dependent on their defense).

## Bivariate EDA

### Points Per Game by Playoff vs. Non-Playoff Teams

```{r}
## Points

ggplot(NBATeamData, aes(x = PlayoffAppearance, y = PTS, fill = PlayoffAppearance)) +
  geom_boxplot(show.legend = FALSE) +
  labs(
    title = "Points per Game by Playoff Appearance",
    x = "",
    y = "Points per Game"
  ) +
  theme_minimal()
```

As previously mentioned it is clear that playoff appearing teams tend to have a higher average score each season than teams that do not make the playoffs by almost 5 points per game.


### Field Goal Percentage by Playoff Teams vs. Non-Playoff Teams

```{r}
## Field Goal Pct

ggplot(NBATeamData, aes(x = PlayoffAppearance, y = FG_PCT, fill = PlayoffAppearance)) +
  geom_boxplot(show.legend = FALSE) +
  labs(
    title = "Field Goal Percentage by Playoff Appearance",
    x = "",
    y = "Field Goal Percentage"
  ) +
  theme_minimal()

```

Another seemingly high impact variable is field goal percentage and it is clear that teams which made the playoffs tended to have an almost 2% better field goal percentage than non-playoff teams.


### Turnovers by Playoff vs. Non-Playoff Teams

```{r}
## Turnovers

ggplot(NBATeamData, aes(x = PlayoffAppearance, y = TOV, fill = PlayoffAppearance)) +
  geom_boxplot(show.legend = FALSE) +
  labs(
    title = "Turnovers per Game by Playoff Appearance",
    x = "",
    y = "Turnovers per Game"
  ) +
  theme_minimal()

```

Another variable that may have been overlooked earlier is turnovers. It is clear that playoff teams turn the ball over less than non-playoff teams. This highlights that other variables besides points scored could be a great indicator of whether a team will be successful.


### Win % vs 2-Point and 3-Point Shooting

```{r}
## Win % vs overall FG%

ggplot(NBATeamData, aes(x = FG_PCT, y = WINPCT, color = PlayoffAppearance)) +
  geom_point(alpha = 0.6) +
  geom_smooth(se = FALSE) +
  labs(
    title = "Win Percentage vs Field Goal Percentage",
    x = "Field Goal Percentage",
    y = "Win Percentage",
    color = "Playoffs"
  ) +
  theme_minimal()


## Win % vs 3-point FG%

ggplot(NBATeamData, aes(x = FG3_PCT, y = WINPCT, color = PlayoffAppearance)) +
  geom_point(alpha = 0.6) +
  geom_smooth(se = FALSE) +
  labs(
    title = "Win Percentage vs Three-Point Percentage",
    x = "Three-Point Percentage",
    y = "Win Percentage",
    color = "Playoffs"
  ) +
  theme_minimal()
```

A very interesting graphic that probably highlights more recent trends in NBA scoring / offensive dyanmic is how field goal pct and 3-point field goal percentage impact the win % of a team. It is very clear that as a team has a better three point field goal percentage their win % seems to see a boost as well, even significantly more than just if the same occurs in overall field goal percentage. Win % and field goal percentage seem almost linear, while 3 point field goal percentage and win percentage seem linear up until the upper echelon of three point shooting teams is reached where it seems to increase with win pct % exponentially.


### Blocks and Steals for Playoff vs. Non-Playoff Teams 

```{r}
## Win % vs Steals
ggplot(NBATeamData, aes(x = STL, y = WINPCT, color = PlayoffAppearance)) +
  geom_point(alpha = 0.6) +
  geom_smooth(se = FALSE) +
  labs(
    title = "Win Percentage vs Steals per Game",
    x = "Steals per Game",
    y = "Win Percentage",
    color = "Playoffs"
  ) +
  theme_minimal()


## Win % vs Blocks

ggplot(NBATeamData, aes(x = BLK, y = WINPCT, color = PlayoffAppearance)) +
  geom_point(alpha = 0.6) +
  geom_smooth(se = FALSE) +
  labs(
    title = "Win Percentage vs Blocks per Game",
    x = "Blocks per Game",
    y = "Win Percentage",
    color = "Playoffs"
  ) +
  theme_minimal()
```

Building off earlier these two graphics seem to show that win % is affected by defensive statistics as well. This is clearly seen with blocks as they seem to increase linearly with a teams win% highlighting how defensively strong teams that prevent shots from being put up seem to have better win %.


## Multivariable EDA for all variables

### Correlation Heatmap

Instead of selecting every single numeric variable, we instead do correlations on the percentages of game statistics like field goals or 3 pointers and include the other numeric variables which do not have percentages.

```{r}
num_vars <- NBATeamData %>%
  select(WINPCT, PTS, FG_PCT, FG3_PCT, FTPCT,
         OREB, DREB, REB, AST, STL, BLK, TOV, PLUS_MINUS)
cor_matrix <- cor(num_vars)
GGally::ggcorr(num_vars, label = TRUE)
```

The correlation heatmap shows several clear relationships among team performance variables. `WINPCT` is most strongly correlated with `DREB` (0.40), `FG_PCT` (0.60), and `FG3_PCT` (0.60), suggesting that efficient scoring is closely tied to winning games. There is a perfect correlation with `PLUS_MINUS`, which is exactly what we would expect. Its interesting to see that offensive rebounds and turnovers are negatively correlated with `WINPCT`, `PTS`, `FG_PCT`, and other scoring metrics. Assists and three-point percentage also show moderate positive correlations with `WINPCT`.

Among predictors, strong internal correlations also appear â€” for example, `OREB` is highly correlated with `DREB` (0.80), and `FG_PCT` is moderately correlated with `PTS` (0.40). These relationships indicate some redundancy among variables, meaning multicollinearity may need to be considered later when selecting predictors for the final GLM. Overall, the heatmap supports the idea that offensive efficiency, point differential, and scoring are the strongest statistical drivers of team success.

## GLM Model Building and Analysis

When considering the variables in the dataset, some variables have both attempts and the number made (for three pointers, field goals, etc.). We will use the number made since the attempts do not show the full picture and are still highly correlated with the number made.

Additonally, there is one key assumption to make for the analysis: a team's performance in one given year is independent of their performance in the year prior. We acknowledge that this is not necessarily true in reality and we are taking on this assumption for the purposes of the project.


To start the model building process, we will make an 80/20 split for the data and define the sets of variables.

```{r}
# make split
set.seed(0) # for reproducibility
idx = sample(1:nrow(NBATeamData), floor(0.8*nrow(NBATeamData)))
train = NBATeamData[idx,]
val = NBATeamData[-idx,]

defense = c("DREB", "STL", "BLK", "PF", "PlayoffAppearanceIndicator")
offense = c("FGM", "FTM", "AST", "OREB", "BLKA", "TOV", "PTS", "PlayoffAppearanceIndicator")
both = c(defense, offense)[-13] # remove second indicator
```

Now we will define the training sets for the three models, build the null and full models, then run stepwise selection with AIC as the criterion.

```{r}
train_defense = train %>% select(all_of(defense))
train_offense = train %>% select(all_of(offense))
train_all = train %>% select(all_of(both))

defense_full = glm(PlayoffAppearanceIndicator ~ ., data = train_defense, family = binomial)
defense_null = glm(PlayoffAppearanceIndicator ~ 1, data = train_defense, family = binomial)
offense_full = glm(PlayoffAppearanceIndicator ~ ., data = train_offense, family = binomial)
offense_null = glm(PlayoffAppearanceIndicator ~ 1, data = train_offense, family = binomial)
all_full = glm(PlayoffAppearanceIndicator ~ ., data = train_all, family = binomial)
all_null = glm(PlayoffAppearanceIndicator ~ 1, data = train_all, family = binomial)

defense_final = step(defense_null, scope = list(lower = defense_null, upper = defense_full), direction = 'both', k = 2, trace = 0)
offense_final = step(offense_null, scope = list(lower = offense_null, upper = offense_full), direction = 'both', k = 2, trace = 0)
all_final = step(all_null, scope = list(lower = all_null, upper = all_full), direction = 'both', k = 2, trace = 0)
```

Lets now take a look at the three final models produced and the predictor variables included, starting with the defense model. 

```{r}
summary(defense_final)

# check multicollinearity
car::vif(defense_final)
```

In the model that only uses the defensive variables to predict playoff appearances for a team, we see that only defensive rebound and steals are significant predictors at the 5\% level. The negative on the `PF` coefficient indicates that personal fouls reduce the odds of winning. We will exponentiate the model coefficients for more interpretable meanings and confidence intervals. Multicollinearity is also not an issue in this model as all the variance inflation factors are near 1.

```{r}
exp(confint(defense_final))
```

Using profile confidence intervals at a 95\% confidence level, we can interpret the coefficients as such: a 1 rebound increase in the defensive rebound mean changes the odds of making the playoffs by a factor between 1.20 and 1.57, each +1 increase in the steal mean changes the odds of making the playoffs by a factor between 1.32 and 2.45, each +1 increase in the mean personal fouls changes the odds of making the playoffs by a factor between 0.68 and 0.96 which is a reduction, and finally each +1 block in the mean changes the odds of making it to the playoffs by a factor between 0.97 and 1.88. 

Next, we will examine the model with only offensive variables. 

```{r}
summary(offense_final)

car::vif(offense_final)
```

Here, we see 4 predictors: blocks against, free throws made, turnovers, and field goals made, of which only two are significant at the 5\% level with blocks against and free throws made being the most significant. Blocks against and turnovers are negative indicating a reduction in the log odds and odds. Like before, multicollinearity is also not an issue in this model as all the variance inflation factors are near 1.

```{r}
exp(confint(offense_final))
```

At a 95\% confidence level, we can make the following inferencs. For a +1 increase in the mean blocks against, the odds of making the playoffs changes byt a factor between 0.16 and 0.39, indicating a reduction in odds. For a +1 increase in mean free throws made, the odds of making the playoffs change by a factor between 1.23 and 1.69. For a +1 increase in mean turnovers, the odds of making it to the playoffs change by a factor between 0.60 and 0.96, indicating a reduction in odds. Finally for a +1 increase in mean field goals made, the odds of making it to the playoffs change by a factor between 0.98 and 1.20.

Finally, we will consider the final model including both sets of variables.

```{r}
summary(all_final)

car::vif(all_final)
```

When we consider the model created with both sets of variables, the picture changes. Out of all 12 variables, only 7 were selected and only 5 are significant predictors at the 5\% level. The 5 significant predictors are blocks against, free throws made, turnovers, steals, defensive rebounds. Just like the two previous models, multicollinearity is not an issue in this model as all the variance inflation factors are near 1. The highest value is 1.70, but this is still a healthy metric for multiple regression models. 

```{r}
exp(confint(all_final))
```
At a 95\% confidence level, we can make inferences in the same manner as above but what is more interesting is seeing which statistics reduce the odds of making it to the playoffs, and which ones increase odds. Team statistics that significantly reduce odds of winning for a +1 increase in mean statistic are blocks against and turnovers, while the variables that significantly increase the odds of making the playoffs for a +1 increase mean stats are free throws made, steals, and defensive rebounds.

Now we will use the models to make predictions and show confusion matrices as well as ROC curves, to compare predictive strength. Of course, we expect the model with both sets of variables to perform the best, but it is still in our interest to compare the 'offense model' again the 'defense model'

```{r}
pprobs_defense = predict(defense_final, newdata = val, type = "response")
pprobs_offense = predict(offense_final, newdata = val, type = "response")
pprobs_all     = predict(all_final,     newdata = val, type = "response")

# set threshold at 0.5 
thr = 0.5

pred_def  = ifelse(pprobs_defense >= thr, 1, 0)
pred_off  = ifelse(pprobs_offense >= thr, 1, 0)
pred_all  = ifelse(pprobs_all     >= thr, 1, 0)

cm_def = confusionMatrix(factor(pred_def), factor(val$PlayoffAppearanceIndicator), positive = "1")
cm_off = confusionMatrix(factor(pred_off), factor(val$PlayoffAppearanceIndicator), positive = "1")
cm_all = confusionMatrix( factor(pred_all), factor(val$PlayoffAppearanceIndicator), positive = "1")

# Extract convenience metrics
metrics = data.frame(
  Model     = c("Defense", "Offense", "Combined"),
  Accuracy  = c(cm_def$overall["Accuracy"],  cm_off$overall["Accuracy"],  cm_all$overall["Accuracy"]),
  Precision = c(cm_def$byClass["Precision"], cm_off$byClass["Precision"], cm_all$byClass["Precision"]),
  Recall    = c(cm_def$byClass["Recall"],    cm_off$byClass["Recall"],    cm_all$byClass["Recall"]),
  F1        = c(cm_def$byClass["F1"],        cm_off$byClass["F1"],        cm_all$byClass["F1"])
)

print(metrics)
```

For all of the metrics above, the offense model actually outperformed the defense model.  

Now we will look at the ROC Curves and compare the AUC of the models.

```{r, message = FALSE}
roc_def = roc(val$PlayoffAppearanceIndicator, pprobs_defense)
roc_off = roc(val$PlayoffAppearanceIndicator, pprobs_offense)
roc_all = roc(val$PlayoffAppearanceIndicator, pprobs_all)
```

```{r}
plot(roc_def, col = "red", legacy.axes = TRUE, print.auc = TRUE, print.auc.y = 0.4)
plot(roc_off, col = "blue", add = TRUE, print.auc = TRUE, print.auc.y = 0.3)
plot(roc_all, col = "darkgreen", add = TRUE, print.auc = TRUE, print.auc.y = 0.2)

legend("bottomright",
       legend = c("Defense", "Offense", "Combined"),
       col    = c("red", "blue", "darkgreen"),
       lwd    = 2)
```

The ROC curves show that both defense and offense are necessary to predict playoff appearances in NBA teams. Although in this case, the offense model has a much higher AUC (by 0.08), we acknowledge that this is highly sensitive to the seed used and a more thorough analysis should utilize cross validation or Monte Carlo simulation to produce a more complete picture of how these statistics behave and what their true predictive powers are, when separating offensive and defensive team statistics.


# MLM Chapter